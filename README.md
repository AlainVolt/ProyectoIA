# Mantenimiento Predictivo de M√°quinas

## Descripci√≥n del problema
¬øPodemos predecir a tiempo si una m√°quina sufrir√° una falla conociendo las lecturas de diferentes tipos de sensores como temperatura, velocidad de rotaci√≥n, etc?

El objetivo con este proyecto es lograr predecir estas fallas a tiempo, para as√≠ realizar la debida mantenci√≥n y evitar costos mayores.

## Dataset
- Fuente: [Kaggle ‚Äì Machine Predictive Maintenance Dataset](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification)
- Este dataset contiene datos asociados a lecturas de sensores, los cuales dan informaci√≥n respecto a las condiciones operativas de m√°quinas en la industria. Este dataset tiene 10000 data points almacenados como filas con 14 features en columnas.
La variable objetivo es Machine failure, la cual es binaria, donde: 0 = no hay falla, 1 = hay falla.

#### üìÑ Features disponibles

| Feature              | Tipo        | Descripci√≥n |
|------------------------|-------------|-------------|
| `UDI`                 | Num√©rica     | Identificador √∫nico del registro. |
| `Product ID`          | Categ√≥rica   | ID del producto. |
| `Type`                | Categ√≥rica   | Tipo de producto A, B o C. |
| `Air temperature [K]` | Num√©rica     | Temperatura del aire en Kelvin. |
| `Process temperature [K]` | Num√©rica | Temperatura del proceso interno. |
| `Rotational speed [rpm]` | Num√©rica  | Velocidad de rotaci√≥n del eje de la m√°quina. |
| `Torque [Nm]`         | Num√©rica     | Fuerza de torsi√≥n aplicada. |
| `Tool wear [min]`     | Num√©rica     | Minutos acumulados de desgaste de herramienta. |
| `Target` (`Machine failure`) | Binaria | Variable objetivo: 0 = no hay falla, 1 = hay falla. |
| `Failure Type`        | Categ√≥rica   | Tipo espec√≠fico de falla. |

Solo se utilizar√°n como **features** las variables num√©ricas relevantes (temperaturas, torque, velocidad, desgaste), junto con `Type` codificada. Se excluir√°n `UDI`, `Product ID` y `Failure Type`.

## Modelo seleccionado
- Random Forest

## Estrategia de evaluaci√≥n
El modelo se evaluar√° utilizando una divisi√≥n de los datos en un 80% para entrenamiento y 20% para testeo, manteniendo el balance de clases. 


Las m√©tricas utilizadas ser√°n:
- Accuracy: para medir el desempe√±o general.
- Precision: para saber cu√°ntas predicciones positivas son correctas.
- Recall: para medir cu√°ntas fallas reales se logran detectar.
- F1-score: equilibrio entre precisi√≥n y recall.
- Matriz de confusi√≥n: para visualizar errores de clasificaci√≥n.

Estas m√©tricas permitir√°n evaluar el desempe√±o del modelo, logrando as√≠ verificar que tan bien identifica las fallas reales y si minimiza falsas alarmas, algo fundamental en un sistema de mantenimiento predictivo.


## Justificaci√≥n del modelo
- Ventajas: Random Forest es un modelo robusto que maneja bien relaciones no lineales entre variables, puede trabajar con variables tanto num√©ricas como categ√≥ricas, y puede determinar la importancia de cada variable. Adem√°s, es menos sensible al overfitting que otros modelos como los √°rboles de decisi√≥n simples.
- Limitaciones: Al tratarse de un modelo de caja negra puede ser m√°s dif√≠cil de interpretar que un √°rbol de decisi√≥n simple, y consume m√°s recursos computacionales. No es muy apto para datasets extremadamente grandes o con muchos atributos irrelevantes.
- Pertinencia: El dataset contiene relaciones probablemente no lineales entre sensores y fallas, lo que hace que un modelo como Random Forest sea el m√°s adecuado. Adem√°s, permite manejar diversos tipos de features y puede integrarse f√°cilmente en entornos industriales reales.

## Metodolog√≠a aplicada

1. Carga y exploraci√≥n inicial de los datos
   - Se revisar√° la estructura del dataset, los tipos de variables que presenta, y si tiene valores faltantes o inconsistentes.
2. An√°lisis exploratorio (EDA)
   - Se analizaran las distribuciones de las variables que son num√©ricas, el balance de clases en la variable objetivo y la correlaci√≥n entre sensores.
3. Preprocesamiento y feature engineering
   - Se eliminar√°n columnas irrelevantes para la predicci√≥n, como `UDI` y `Product ID`.
   - Se codificar√° en binario la variable categ√≥rica `Type`.
   - Se normalizar√°n las variables num√©ricas de ser necesario.
4. Selecci√≥n del modelo y entrenamiento
   - Se entrenar√° un modelo de Random Forest con el conjunto de entrenamiento.
   - Se realizar√° la divisi√≥n de los datos en 80/20.
5. Control de overfitting
   - Se ajustar√°n hiper par√°metros como `max_depth`, `n_estimators` y `min_samples_split`.
   - Se usar√° validaci√≥n cruzada (Cross-Validation) para evaluar la robustez del modelo.
6. Evaluaci√≥n del modelo mediante m√©tricas
   - Se calcular√°n m√©tricas como accuracy, precision, recall, F1-score.
   - Se construir√° una Matriz de Confusi√≥n y una Curva ROC.
7. Visualizaci√≥n de resultados
   - Se graficar√°n m√©tricas y se presentar√° la importancia de cada variable (feature-importances) para la predicci√≥n.

## Resultados

En el proyecto se compararon tres modelos diferentes entrenados para lograr predecir fallas en m√°quinas.
A continuaci√≥n se presentan los resultados obtenidos en cada modelo.

### 1. Decision Tree (base)
**Accuracy**: 0.98

| **M√©trica**    | **Clase 0 (No falla)** | **Clase 1 (Falla)** | **Macro avg** | **Weighted avg** |
|----------------|------------------------|----------------------|----------------|------------------|
| **Precision**  | 0.99                   | 0.68                 | 0.83           | 0.98             |
| **Recall**     | 0.99                   | 0.66                 | 0.83           | 0.98             |
| **F1-score**   | 0.99                   | 0.67                 | 0.83           | 0.98             |

**Confusion matrix**:


![Matriz de Confusi√≥n DT](img/matriz_confusion_dt.png)

- **Observaci√≥n**: en general notamos que se presenta una muy alta exactitud, sin embargo, esto probablemente se debe a que hay una clase mayoritaria muy marcada (no falla). La capacidad que posee para detectar fallas es limitada, esto se refleja claramente en el F1 de la clase 1.

### 2. Random Forest (base)
**Accuracy**: 0.98

| **M√©trica**    | **Clase 0 (No falla)** | **Clase 1 (Falla)** | **Macro avg** | **Weighted avg** |
|----------------|------------------------|----------------------|----------------|------------------|
| **Precision**  | 0.98                   | 0.88                 | 0.93           | 0.98             |
| **Recall**     | 1.00                   | 0.53                 | 0.76           | 0.98             |
| **F1-score**   | 0.99                   | 0.66                 | 0.83           | 0.98             |

**Confusion matrix**:


![Matriz de Confusi√≥n RF](img/matriz_confusion_rf_base.png)

- **Observaci√≥n**: al aplicar Random Forest  base, es decir, con n_estimators = 100 y el resto de par√°metros por default, se logr√≥ una leve mejora sobre el √°rbol de decisi√≥n, especialmente en el F1-score de la clase minoritaria.

### 3. Random Forest (optimizado)
**Accuracy**: 0.98

| **M√©trica**    | **Clase 0 (No falla)** | **Clase 1 (Falla)** | **Macro avg** | **Weighted avg** |
|----------------|------------------------|----------------------|----------------|------------------|
| **Precision**  | 0.99                   | 0.71                 | 0.85           | 0.98             |
| **Recall**     | 0.99                   | 0.69                 | 0.84           | 0.98             |
| **F1-score**   | 0.99                   | 0.70                 | 0.85           | 0.98             |

**Confusion matrix**: 


![Matriz de Confusi√≥n RF opt](img/matriz_confusion_rf_opt.png)


**ROC AUC**: 0.9650468883205456


![ROC AUC](img/AUC_ROC_RF.png)

**Importances**:
![Importances](img/Importances.png)

- **Observaci√≥n**: este modelo fue, sin duda alguna, el m√°s equilibrado y robusto. Gracias al ajuste de hiper par√°metros (`n_estimators`, `max_depth`, `min_samples_split`) mediante el uso de grid-search, se logr√≥ mejorar el F1-score sin alterar demasiado la precisi√≥n global. El resultado fue un modelo m√°s sensible a fallas reales sin overfitting.

### Sobre las gr√°ficas
- **Matriz de confusi√≥n**: nos permiti√≥ evidenciar los tipos de errores cometidos por cada modelo.
- **Curva ROC y AUC**: nos mostraron que el modelo de Random Forest es mucho mejor para discriminar correctamente entre clases.
- **Importancia de variables**: gracias a lo observado en esta gr√°fica, identificamos que `Tool wear`, `Torque` y `Process temperature` son las features m√°s relevantes a la hora de anticipar fallas en las m√°quinas.

### Discusi√≥n cr√≠tica

El √Årbol de Decisi√≥n fue √∫til como modelo de referencia, pero su desempe√±o en la clase minoritaria fue bien limitado. En cambio, con Random Forest, se pudo notar como este trajo mejoras evidentes gracias a su gran capacidad para modelar relaciones no lineales y mitigar el desbalance al usar `class_weight='balanced'`.

El modelo final, es decir, Random Forest optimizado mediante cross-validation en grid-search, logr√≥ el mejor rendimiento general en el proyecto. Este mantuvo un alto accuracy y una capacidad decente para detectar fallas, esto se puede confirmar al observar sus m√©tricas (F1-score = 0.70, AUC = 0.97). Adem√°s, el an√°lisis de variable importance nos sirvi√≥ para obtener una mejor interpretabilidad sobre qu√© condiciones operativas son m√°s cr√≠ticas al momento de determinar si una m√°quina requiere mantenimiento o no. Cabe mencionar, que aunque obtuvimos las features m√°s relevantes relacionadas a fallas, estas tuvieron valores no tan altos en importancia, donde Torque logr√≥ el mayor valor, siendo de 0.35 aproximadamente.

Estos resultados validan el uso de Random Forest como soluci√≥n efectiva y confiable para mantenimiento predictivo en entornos industriales. Y de esta manera, logrando reducir costos.


## Conclusiones

- A trav√©s del presente proyecto se desarroll√≥ un sistema de mantenimiento predictivo capaz de anticipar fallas en m√°quinas industriales, utilizando modelos de clasificaci√≥n supervisada entrenados con lecturas de diferentes tipos de sensores, como torque, temperatura y desgaste de herramienta (tool wear), entre otros.

- El modelo base, es decir, el √Årbol de Decisi√≥n, entreg√≥ buenos resultados iniciales, pero demostr√≥ bastantes limitaciones en cuanto a la detecci√≥n de fallas, esto debido al desbalance de clases.

- El modelo de Random Forest optimizado con cross-validation y ajuste de hiper par√°metros mostr√≥ un rendimiento significativamente superior, alcanzando un F1-score de 0.70 en la clase de fallas y un AUC de 0.97 aproximadamente. Adem√°s, el uso del par√°metro `class_weight='balanced'` nos permiti√≥ compensar eficazmente el desbalance sin tener que obligarnos a eliminar datos importantes.

- Las diferentes m√©tricas obtenidas y las gr√°ficas asociadas (matriz de confusi√≥n, curva ROC y variable importance) nos confirmaron que el modelo tiene una alta capacidad de generalizaci√≥n, con un buen potencial para ser efectivo en aplicaciones industriales tras testeo previo en entornos reales.

- Finalmente, concluimos que la combinaci√≥n de buenas pr√°cticas en preprocesamiento, selecci√≥n de caracter√≠sticas, cross-validation y an√°lisis de resultados nos permiti√≥ construir un modelo robusto, preciso e interpretable para mantenimiento predictivo.



## Autores
Diego Avenda√±o y Braulio Silva
