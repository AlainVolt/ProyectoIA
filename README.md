# Mantenimiento Predictivo de M√°quinas

## Descripci√≥n del problema
¬øPodemos predecir a tiempo si una m√°quina sufrir√° una falla conociendo las lecturas de diferentes tipos de sensores como temperatura, velocidad de rotaci√≥n, etc?

El objetivo con este proyecto es lograr predecir estas fallas a tiempo, para as√≠ realizar la debida mantenci√≥n y evitar costos mayores.

## Dataset
- Fuente: [Kaggle ‚Äì Machine Predictive Maintenance Dataset](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification)
- Este dataset contiene datos asociados a lecturas de sensores, los cuales dan informaci√≥n respecto a las condiciones operativas de m√°quinas en la industria. Este dataset tiene 10000 data points almacenados como filas con 14 features en columnas.
La variable objetivo es Machine failure, la cual es binaria, donde: 0 = no hay falla, 1 = hay falla.

#### üìÑ Features disponibles

| Feature              | Tipo        | Descripci√≥n |
|------------------------|-------------|-------------|
| `UDI`                 | Num√©rica     | Identificador √∫nico del registro. |
| `Product ID`          | Categ√≥rica   | ID del producto. |
| `Type`                | Categ√≥rica   | Tipo de producto A, B o C. |
| `Air temperature [K]` | Num√©rica     | Temperatura del aire en Kelvin. |
| `Process temperature [K]` | Num√©rica | Temperatura del proceso interno. |
| `Rotational speed [rpm]` | Num√©rica  | Velocidad de rotaci√≥n del eje de la m√°quina. |
| `Torque [Nm]`         | Num√©rica     | Fuerza de torsi√≥n aplicada. |
| `Tool wear [min]`     | Num√©rica     | Minutos acumulados de desgaste de herramienta. |
| `Target` (`Machine failure`) | Binaria | Variable objetivo: 0 = no hay falla, 1 = hay falla. |
| `Failure Type`        | Categ√≥rica   | Tipo espec√≠fico de falla. |

Solo se utilizar√°n como **features** las variables num√©ricas relevantes (temperaturas, torque, velocidad, desgaste), junto con `Type` codificada. Se excluir√°n `UDI`, `Product ID` y `Failure Type`.

## Modelo seleccionado
- Random Forest

## Estrategia de evaluaci√≥n
El modelo se evaluar√° utilizando una divisi√≥n de los datos en un 80% para entrenamiento y 20% para testeo, manteniendo el balance de clases. 


Las m√©tricas utilizadas ser√°n:
- Accuracy: para medir el desempe√±o general.
- Precision: para saber cu√°ntas predicciones positivas son correctas.
- Recall: para medir cu√°ntas fallas reales se logran detectar.
- F1-score: equilibrio entre precisi√≥n y recall.
- Matriz de confusi√≥n: para visualizar errores de clasificaci√≥n.

Estas m√©tricas permitir√°n evaluar el desempe√±o del modelo, logrando as√≠ verificar que tan bien identifica las fallas reales y si minimiza falsas alarmas, algo fundamental en un sistema de mantenimiento predictivo.


## Justificaci√≥n del modelo
- Ventajas: Random Forest es un modelo robusto que maneja bien relaciones no lineales entre variables, puede trabajar con variables tanto num√©ricas como categ√≥ricas, y puede determinar la importancia de cada variable. Adem√°s, es menos sensible al overfitting que otros modelos como los √°rboles de decisi√≥n simples.
- Limitaciones: Al tratarse de un modelo de caja negra puede ser m√°s dif√≠cil de interpretar que un √°rbol de decisi√≥n simple, y consume m√°s recursos computacionales. No es muy apto para datasets extremadamente grandes o con muchos atributos irrelevantes.
- Pertinencia: El dataset contiene relaciones probablemente no lineales entre sensores y fallas, lo que hace que un modelo como Random Forest sea el m√°s adecuado. Adem√°s, permite manejar diversos tipos de features y puede integrarse f√°cilmente en entornos industriales reales.

## Metodolog√≠a aplicada

1. Carga y exploraci√≥n inicial de los datos
   - Se revisar√° la estructura del dataset, los tipos de variables que presenta, y si tiene valores faltantes o inconsistentes.
2. An√°lisis exploratorio (EDA)
   - Se analizaran las distribuciones de las variables que son num√©ricas, el balance de clases en la variable objetivo y la correlaci√≥n entre sensores.
3. Preprocesamiento y feature engineering
   - Se eliminar√°n columnas irrelevantes para la predicci√≥n, como `UDI` y `Product ID`.
   - Se codificar√° en binario la variable categ√≥rica `Type`.
   - Se normalizar√°n las variables num√©ricas de ser necesario.
4. Selecci√≥n del modelo y entrenamiento
   - Se entrenar√° un modelo de Random Forest con el conjunto de entrenamiento.
   - Se realizar√° la divisi√≥n de los datos en 80/20.
5. Control de overfitting
   - Se ajustar√°n hiper par√°metros como `max_depth`, `n_estimators` y `min_samples_split`.
   - Se usar√° validaci√≥n cruzada (Cross-Validation) para evaluar la robustez del modelo.
6. Evaluaci√≥n del modelo mediante m√©tricas
   - Se calcular√°n m√©tricas como accuracy, precision, recall, F1-score.
   - Se construir√° una Matriz de Confusi√≥n y una Curva ROC.
7. Visualizaci√≥n de resultados
   - Se graficar√°n m√©tricas y se presentar√° la importancia de cada variable (feature-importances) para la predicci√≥n.

## Autores
Diego Avenda√±o y Braulio Silva
